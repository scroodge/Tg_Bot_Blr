import os
import sys
import threading
from typing import Optional

import platform
import traceback
import transformers as _tf
import huggingface_hub as _hf

import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from transformers.utils import logging as hf_logging
from tqdm import tqdm
from telegram import Update, InlineQueryResultArticle, InputTextMessageContent
from telegram.ext import Application, CommandHandler, MessageHandler, InlineQueryHandler, filters, ContextTypes
from uuid import uuid4

ENV_PATH = ".env"

def load_or_ask_token() -> str:
    token = os.environ.get("TELEGRAM_BOT_TOKEN")
    if token:
        return token.strip()

    # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑ .env
    if os.path.exists(ENV_PATH):
        with open(ENV_PATH, "r", encoding="utf-8") as f:
            for line in f:
                if line.startswith("TELEGRAM_BOT_TOKEN="):
                    token = line.split("=", 1)[1].strip()
                    if token:
                        os.environ["TELEGRAM_BOT_TOKEN"] = token
                        return token

    # –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω–∞ –Ω–µ—Ç ‚Äî –∑–∞–ø—Ä–æ—Å–∏–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 1 —Ä–∞–∑ –∏ —Å–æ—Ö—Ä–∞–Ω–∏–º
    print("–í—Å—Ç–∞–≤—å—Ç–µ —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –æ—Ç @BotFather –∏ –Ω–∞–∂–º–∏—Ç–µ Enter:")
    token = input().strip()
    if not token:
        print("–¢–æ–∫–µ–Ω –ø—É—Å—Ç. –í—ã—Ö–æ–¥.")
        sys.exit(1)

    with open(ENV_PATH, "w", encoding="utf-8") as f:
        f.write(f"TELEGRAM_BOT_TOKEN={token}\n")
    os.environ["TELEGRAM_BOT_TOKEN"] = token
    return token

# –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —á–µ—Ä–µ–∑ transformers –¥–ª—è –∞–±—Å–æ–ª—é—Ç–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
class PreciseTranslator:
    def __init__(self):
        model_name = os.getenv("RU_BE_MODEL", "Helsinki-NLP/opus-mt-ru-be")
        cache_dir = os.getenv("HF_CACHE_DIR", os.path.expanduser("~/.cache/huggingface"))
        local_only = os.getenv("HF_LOCAL_ONLY", "0") == "1"
        print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å {model_name}... (local_only={local_only}, cache_dir={cache_dir})")

        is_local_path = os.path.isdir(model_name)
        print(f"üîé is_local_path={is_local_path}")
        if is_local_path:
            print(f"üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ –º–æ–¥–µ–ª–∏: {model_name}")
            try:
                print("   ", os.listdir(model_name)[:10])
            except Exception as ee:
                print("   (–Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞—Ç–∞–ª–æ–≥)", ee)

        def _suggest_alternatives():
            try:
                from huggingface_hub import HfApi
                api = HfApi()
                # –ò—â–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã ru‚Üíbe –æ—Ç Helsinki-NLP
                cands = api.list_models(search="ru-be", author="Helsinki-NLP")
                if not cands:
                    cands = api.list_models(search="opus-mt be", author="Helsinki-NLP")
                if cands:
                    print("üîé –ú–∞–≥—á—ã–º–∞—è –ø–∞–¥–º–µ–Ω–∞ —ñ–¥—ç–Ω—Ç—ã—Ñ—ñ–∫–∞—Ç–∞—Ä–∞. –ü—Ä–∞–≤–µ—Ä—Ü–µ –≥—ç—Ç—ã—è –º–∞–¥—ç–ª—ñ:")
                    for m in cands[:10]:
                        print("   ‚Ä¢", m.modelId)
                else:
                    print("üîé –ê–ª—å—Ç—ç—Ä–Ω–∞—Ç—ã–≤—ã –Ω–µ –∑–Ω–æ–π–¥–∑–µ–Ω—ã –ø—Ä–∞–∑ API. –ü–∞—Å–ø—Ä–∞–±—É–π—Ü–µ –ø–æ—à—É–∫ –Ω–∞ huggingface.co –ø–∞ 'ru-be opus-mt'.")
            except Exception as ee:
                print(f"(debug) –ù–µ —û–¥–∞–ª–æ—Å—è –∞—Ç—Ä—ã–º–∞—Ü—å —Å–ø—ñ—Å –º–∞–¥—ç–ª—è—û: {ee}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: —Å–Ω–∞—á–∞–ª–∞ MPS (Apple Silicon), –∑–∞—Ç–µ–º CUDA, –∑–∞—Ç–µ–º CPU
        if torch.backends.mps.is_available():
            self.device = torch.device("mps")
        elif torch.cuda.is_available():
            self.device = torch.device("cuda")
        else:
            self.device = torch.device("cpu")

        try:
            # –í–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∑–∞–≥—Ä—É–∑–∫–∏
            try:
                import huggingface_hub
                huggingface_hub.utils._validators.disable_progress_bars = False
            except Exception:
                pass
            hf_logging.set_verbosity_info()
            if not local_only and not is_local_path:
                try:
                    print("üåê –ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é –Ω–∞ Hugging Face...")
                    info = _hf.HfApi().model_info(model_name)
                    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å: {info.modelId} (sha: {getattr(info, 'sha', 'n/a')})")
                except Exception as ping_e:
                    print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ API:")
                    print("   ", ping_e)
            print("‚è¨ –ó–∞–≥—Ä—É–∂–∞—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                local_files_only=local_only,
                cache_dir=cache_dir,
                use_auth_token=None
            )
            print("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            try:
                print(f"   üî§ vocab_size={getattr(self.tokenizer, 'vocab_size', 'n/a')}")
                print(f"   BOS={self.tokenizer.bos_token} EOS={self.tokenizer.eos_token} PAD={self.tokenizer.pad_token}")
            except Exception:
                pass
            print("‚è¨ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å (–≤–µ—Å–∞)... —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ")
            self.model = AutoModelForSeq2SeqLM.from_pretrained(
                model_name,
                local_files_only=local_only,
                cache_dir=cache_dir,
                use_auth_token=None
            ).to(self.device)
            self.model.eval()
            print("‚úÖ –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
            try:
                params = sum(p.numel() for p in self.model.parameters())
                print(f"   üßÆ –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: {params:,}")
            except Exception:
                pass
            try:
                if self.device.type == 'cuda':
                    print(f"   üí† CUDA: {torch.cuda.get_device_name(0)}")
                    print(f"     –ø–∞–º—è—Ç—å: {torch.cuda.memory_reserved()/1e6:.1f}MB reserved/{torch.cuda.memory_allocated()/1e6:.1f}MB alloc")
                elif self.device.type == 'mps':
                    print("   üí† MPS –∞–∫—Ç–∏–≤–µ–Ω")
            except Exception:
                pass
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å: pip install transformers torch")
            if not local_only:
                print("üí° –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/–±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è: —Å–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å –≤ ./models/opus-mt-ru-be –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å RU_BE_MODEL=./models/opus-mt-ru-be HF_LOCAL_ONLY=1")
                print("   –ü—Ä–∏–º–µ—Ä: huggingface-cli download Helsinki-NLP/opus-mt-ru-be --local-dir ./models/opus-mt-ru-be")
            _suggest_alternatives()
            print("üí° –ú–æ–∂–Ω–∞ —û—Å—Ç–∞–ª—è–≤–∞—Ü—å –¥–∞–∫–ª–∞–¥–Ω—ã —ñ–¥ –º–∞–¥—ç–ª—ñ –ø—Ä–∞–∑ RU_BE_MODEL=... —ñ –ø–µ—Ä–∞–∑–∞–ø—É—Å—Ü—ñ—Ü—å.")
            print("--- traceback ---")
            traceback.print_exc()
            print("------------------")
            raise

    def translate_ru_to_be(self, text: str, max_len: int = 512) -> str:
        text = text.strip()
        if not text:
            return ""
        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ (–Ω–µ —Ä–∞–≤–Ω–æ –≤—Ö–æ–¥–Ω–æ–π –¥–ª–∏–Ω–µ)
            max_new = 256 if max_len > 256 else max_len

            inputs = self.tokenizer(
                [text],
                return_tensors="pt",
                truncation=True,
                max_length=max_len,
                padding=True,
            ).to(self.device)

            with torch.inference_mode():
                output_tokens = self.model.generate(
                    **inputs,
                    num_beams=4,
                    length_penalty=1.0,
                    max_new_tokens=max_new,
                    early_stopping=True,
                    do_sample=False,
                )

            result = self.tokenizer.batch_decode(
                output_tokens,
                skip_special_tokens=True,
                clean_up_tokenization_spaces=True,
            )[0]
            return result.strip()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
            return f"–ü–∞–º—ã–ª–∫–∞ –ø–µ—Ä–∞–∫–ª–∞–¥—É: {e}"

# Fallback –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å –±–∞–∑–æ–≤—ã–º —Å–ª–æ–≤–∞—Ä–µ–º
class FallbackTranslator:
    def __init__(self):
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        self.translations = {
            "–ø—Ä–∏–≤–µ—Ç": "–ø—Ä—ã–≤—ñ—Ç–∞–Ω–Ω–µ",
            "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ": "–¥–∞–±—Ä—ã–¥–∑–µ–Ω—å",
            "—Å–ø–∞—Å–∏–±–æ": "–¥–∑—è–∫—É–π",
            "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞": "–∫–∞–ª—ñ –ª–∞—Å–∫–∞",
            "–¥–∞": "—Ç–∞–∫",
            "–Ω–µ—Ç": "–Ω–µ",
            "—Ö–æ—Ä–æ—à–æ": "–¥–æ–±—Ä–∞",
            "–ø–ª–æ—Ö–æ": "–¥—Ä—ç–Ω–Ω–∞",
            "–∫–∞–∫ –¥–µ–ª–∞": "—è–∫ —Å–ø—Ä–∞–≤—ã",
            "–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è": "–¥–∞ –ø–∞–±–∞—á—ç–Ω–Ω—è",
            "–∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç": "—è–∫ —Ü—è–±–µ –∑–∞–≤—É—Ü—å",
            "–º–µ–Ω—è –∑–æ–≤—É—Ç": "–º—è–Ω–µ –∑–∞–≤—É—Ü—å",
            "–≥–¥–µ —Ç—ã –∂–∏–≤–µ—à—å": "–¥–∑–µ —Ç—ã –∂—ã–≤–µ—à",
            "—Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç": "–∫–æ–ª—å–∫—ñ —Ç–∞–±–µ –≥–∞–¥–æ—û",
            "–Ω–µ –Ω–∞–¥–æ": "–Ω–µ —Ç—Ä—ç–±–∞",
            "–≤ –∫—Ä–æ–≤–∞—Ç–∏": "—É –ø–∞—Å—Ü–µ–ª—ñ",
            "—Ç–∞–∫ —Ö–æ—Ä–æ—à–æ": "—Ç–∞–∫ –¥–æ–±—Ä–∞",
            "–º–æ—è —Ö–æ—Ä–æ—à–∞—è": "–º–∞—è –¥–∞—Ä–∞–≥–∞—è",
            "–ª—é–±–ª—é —Ç–µ–±—è": "–∫–∞—Ö–∞—é —Ü—è–±–µ",
            "—Å–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏": "—Å–ø–∞–∫–æ–π–Ω–∞–π –Ω–æ—á—ã"
        }
    
    def translate_ru_to_be(self, text: str, max_len: int = 512) -> str:
        text = text.strip().lower()
        if not text:
            return ""
        
        # –ò—â–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if text in self.translations:
            return self.translations[text]
        
        # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        for ru, be in self.translations.items():
            if ru in text:
                return f"–ß–∞—Å—Ç–∫–æ–≤—ã –ø–µ—Ä–∞–∫–ª–∞–¥: {be} (–¥–ª—è '{ru}')"
        
        return "–ü–µ—Ä–∞–∫–ª–∞–¥ –Ω–µ –∑–Ω–æ–π–¥–∑–µ–Ω—ã —û –±–∞–∑–µ. –ü–∞—Å–ø—Ä–∞–±—É–π—Ü–µ —ñ–Ω—à—ã —Ç—ç–∫—Å—Ç."

translator: Optional[PreciseTranslator] = None
fallback_translator: Optional[FallbackTranslator] = None
translator_lock = threading.Lock()

async def ensure_translator():
    global translator, fallback_translator
    
    if translator is None:
        with translator_lock:
            if translator is None:
                try:
                    translator = PreciseTranslator()
                    fallback_translator = FallbackTranslator()
                except Exception as e:
                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫: {e}")
                    print("–ò—Å–ø–æ–ª—å–∑—É—é fallback –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫...")
                    translator = None
                    fallback_translator = FallbackTranslator()
    
    return translator, fallback_translator

# –ö–æ–º–∞–Ω–¥—ã
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = (
        "–ü—Ä—ã–≤—ñ—Ç–∞–Ω–Ω–µ! –Ø –ø–µ—Ä–∞–∫–ª–∞–¥–∞—é –∑ —Ä—É—Å–∫–∞–π –Ω–∞ –±–µ–ª–∞—Ä—É—Å–∫—É—é –∑ –∞–±—Å–∞–ª—é—Ç–Ω–∞–π –¥–∞–∫–ª–∞–¥–Ω–∞—Å—Ü—é üéØ\n\n"
        "‚Ä¢ –ù–∞–ø—ñ—à—ã—Ü–µ –º–Ω–µ —Ç—ç–∫—Å—Ç ‚Äî —è –∞–¥–∫–∞–∂—É –ø–µ—Ä–∞–∫–ª–∞–¥–∞–º.\n"
        "‚Ä¢ –£ –ª—é–±—ã–º —á–∞—Ü–µ —û–≤—è–¥–∑—ñ—Ü–µ: @"
        f"{(await context.bot.get_me()).username} –≤–∞—à —Ä—É—Å–∫—ñ —Ç—ç–∫—Å—Ç ‚Äî —ñ —û—Å—Ç–∞—û—Ü–µ –≤—ã–Ω—ñ–∫.\n\n"
        "–ö—Ä—ã–Ω—ñ—Ü–∞: –ª–∞–∫–∞–ª—å–Ω–∞—è –º–∞–¥—ç–ª—å –ø–µ—Ä–∞–∫–ª–∞–¥—É (–∫–∞–Ω—Ñ—ñ–≥—É—Ä—É–µ—Ü—Ü–∞ –ø—Ä–∞–∑ RU_BE_MODEL).\n"
        "–£ –≤—ã–ø–∞–¥–∫—É –ø–∞–º—ã–ª–∫—ñ –≤—ã–∫–∞—Ä—ã—Å—Ç–æ—û–≤–∞–µ—Ü—Ü–∞ fallback –ø–µ—Ä–∞–∫–ª–∞–¥—á—ã–∫.\n\n"
        "–ö–∞–º–∞–Ω–¥—ã:\n"
        "/start - –ø–∞—á–∞—Ç–∞–∫\n"
        "/help - –¥–∞–ø–∞–º–æ–≥–∞\n"
        "/status - —Å—Ç–∞—Ç—É—Å –º–∞–¥—ç–ª—ñ\n"
        "/test - —Ç—ç—Å—Ç –ø–µ—Ä–∞–∫–ª–∞–¥—É"
    )
    await update.message.reply_text(msg)

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–æ—Å—Ç–∞ –¥–∞—à–ª—ñ—Ü–µ —Ä—É—Å–∫—ñ —Ç—ç–∫—Å—Ç ‚Äî —è –ø–µ—Ä–∞–∫–ª–∞–¥—É –Ω–∞ –±–µ–ª–∞—Ä—É—Å–∫—É—é.\n"
        "–Ü–Ω–ª–∞–π–Ω: @–Ü–º—è–ë–æ—Ç–∞ –≤–∞—à —Ä—É—Å–∫—ñ —Ç—ç–∫—Å—Ç.\n\n"
        "–ë–æ—Ç –≤—ã–∫–∞—Ä—ã—Å—Ç–æ—û–≤–∞–µ –ª–∞–∫–∞–ª—å–Ω—É—é –º–∞–¥—ç–ª—å Helsinki-NLP/opus-mt-ru-be.\n"
        "–ö–∞–º–∞–Ω–¥—ã:\n"
        "/status - —Å—Ç–∞—Ç—É—Å –º–∞–¥—ç–ª—ñ\n"
        "/test - —Ç—ç—Å—Ç –ø–µ—Ä–∞–∫–ª–∞–¥—É"
    )

async def debug_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    from huggingface_hub import HfFolder
    hf_token = HfFolder.get_token()
    cache_dir = os.getenv("HF_CACHE_DIR", os.path.expanduser("~/.cache/huggingface"))
    env_summary = (
        f"HF_ENDPOINT={os.getenv('HF_ENDPOINT','')}\n"
        f"HF_LOCAL_ONLY={os.getenv('HF_LOCAL_ONLY','0')}\n"
        f"RU_BE_MODEL={os.getenv('RU_BE_MODEL','')}\n"
        f"HF_CACHE_DIR={cache_dir}\n"
        f"HF_TOKEN={'set' if hf_token else 'not set'}\n"
    )
    await update.message.reply_text("Debug env:\n" + env_summary)

async def status_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏"""
    global translator
    
    if translator:
        try:
            params = sum(p.numel() for p in translator.model.parameters())
        except Exception:
            params = None
        device = getattr(translator, "device", "cpu")
        msg = (
            "‚úÖ –ú–∞–¥—ç–ª—å Helsinki-NLP/opus-mt-ru-be –∑–∞–≥—Ä—É–∂–∞–Ω–∞ —ñ –ø—Ä–∞—Ü—É–µ\n\n"
            f"–¢–æ–∫–µ–Ω—ñ–∑–∞—Ç–∞—Ä: {type(translator.tokenizer).__name__}\n"
            f"–ú–∞–¥—ç–ª—å: {type(translator.model).__name__}\n"
            f"–ü—Ä—ã–ª–∞–¥–∞: {device}\n"
        )
        if params is not None:
            msg += f"–ü–∞—Ä–∞–º–µ—Ç—Ä–∞—û: {params:,}"
        msg += f"–ö—ç—à: {os.getenv('HF_CACHE_DIR', os.path.expanduser('~/.cache/huggingface'))}\n"
    else:
        msg = f"‚ùå –ú–∞–¥—ç–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞\nüí° –í—ã–∫–∞—Ä—ã—Å—Ç–æ—û–≤–∞–µ—Ü—Ü–∞ fallback –ø–µ—Ä–∞–∫–ª–∞–¥—á—ã–∫ (–∫–∞–Ω—Ñ—ñ–≥—É—Ä—É–µ—Ü—Ü–∞ –ø—Ä–∞–∑ RU_BE_MODEL, –ø–∞ –∑–º–∞—û—á–∞–Ω–Ω—ñ Helsinki-NLP/opus-mt-ru-be)"
    
    await update.message.reply_text(msg)

async def test_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞"""
    if not context.args:
        await update.message.reply_text(
            "–í—ã–∫–∞—Ä—ã—Å—Ç–æ—û–≤–∞–π—Ü–µ: /test <—Ä—É—Å–∫—ñ —Ç—ç–∫—Å—Ç>\n\n"
            "–ü—Ä—ã–∫–ª–∞–¥: /test –∫–∞–∫ –¥–µ–ª–∞ –º–æ—è —Ö–æ—Ä–æ—à–∞—è"
        )
        return
    
    test_text = " ".join(context.args)
    precise_tr, fallback_tr = await ensure_translator()
    
    if precise_tr:
        await update.message.reply_text(f"üéØ –¢—ç—Å—Ç –¥–∞–∫–ª–∞–¥–Ω–∞–≥–∞ –ø–µ—Ä–∞–∫–ª–∞–¥—É:\n\n–†—É—Å–∫—ñ: {test_text}\n\n–ü–µ—Ä–∞–∫–ª–∞–¥–∞—é...")
        
        try:
            be = precise_tr.translate_ru_to_be(test_text)
            await update.message.reply_text(f"–ë–µ–ª–∞—Ä—É—Å–∫—ñ: {be}")
        except Exception as e:
            await update.message.reply_text(f"‚ùå –ü–∞–º—ã–ª–∫–∞: {e}")
    else:
        await update.message.reply_text("‚ùå –î–∞–∫–ª–∞–¥–Ω—ã –ø–µ—Ä–∞–∫–ª–∞–¥—á—ã–∫ –Ω–µ –¥–∞—Å—Ç—É–ø–Ω—ã")

# –ü–µ—Ä–µ–≤–æ–¥ –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    precise_tr, fallback_tr = await ensure_translator()
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ç–æ–º, —á—Ç–æ –ø–µ—Ä–µ–≤–æ–¥ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
    wait_message = await update.message.reply_text("üéØ –ü–µ—Ä–∞–∫–ª–∞–¥–∞—é –∑ –¥–∞–∫–ª–∞–¥–Ω–∞—Å—Ü—é...")
    
    try:
        if precise_tr:
            # –ü—Ä–æ–±—É–µ–º —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫
            be = precise_tr.translate_ru_to_be(text)
            if be and not be.startswith("–ü–∞–º—ã–ª–∫–∞"):
                # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ–∂–∏–¥–∞–Ω–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
                await wait_message.delete()
                await update.message.reply_text(be)
                return
        
        # –ï—Å–ª–∏ —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
        be = fallback_tr.translate_ru_to_be(text)
        if not be or be.startswith("–ü–µ—Ä–∞–∫–ª–∞–¥ –Ω–µ –∑–Ω–æ–π–¥–∑–µ–Ω—ã"):
            be = "–ü–µ—Ä–∞–∫–ª–∞–¥ –Ω–µ –∞—Ç—Ä—ã–º–∞—û—Å—è. –ü–∞—Å–ø—Ä–∞–±—É–π—Ü–µ —ñ–Ω—à—ã —Ç—ç–∫—Å—Ç."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ–∂–∏–¥–∞–Ω–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
        await wait_message.delete()
        await update.message.reply_text(be)
        
    except Exception as e:
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ–∂–∏–¥–∞–Ω–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É
        await wait_message.delete()
        await update.message.reply_text(f"–ü–∞–º—ã–ª–∫–∞ –ø–µ—Ä–∞–∫–ª–∞–¥—É: {e}")

# –ò–Ω–ª–∞–π–Ω-—Ä–µ–∂–∏–º: @BotName <—Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç>
async def on_inline_query(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = (update.inline_query.query or "").strip()
    if not query:
        # –ü–æ–∫–∞–∂–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É-–ø—É—Å—Ç—ã—à–∫—É, —á—Ç–æ–±—ã –±—ã–ª–æ —á—Ç–æ –≤—ã–±—Ä–∞—Ç—å
        results = [
            InlineQueryResultArticle(
                id=str(uuid4()),
                title="–£–≤—è–¥–∑—ñ—Ü–µ —Ä—É—Å–∫—ñ —Ç—ç–∫—Å—Ç",
                input_message_content=InputTextMessageContent("–£–≤—è–¥–∑—ñ—Ü–µ —Ä—É—Å–∫—ñ —Ç—ç–∫—Å—Ç –¥–ª—è –ø–µ—Ä–∞–∫–ª–∞–¥—É."),
                description="–Ø –ø–µ—Ä–∞–∫–ª–∞–¥—É –Ω–∞ –±–µ–ª–∞—Ä—É—Å–∫—É—é –∑ –¥–∞–∫–ª–∞–¥–Ω–∞—Å—Ü—é"
            )
        ]
        await update.inline_query.answer(results, cache_time=0, is_personal=True)
        return

    precise_tr, fallback_tr = await ensure_translator()
    
    try:
        if precise_tr:
            # –ü—Ä–æ–±—É–µ–º —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫
            be = precise_tr.translate_ru_to_be(query)
            if be and not be.startswith("–ü–∞–º—ã–ª–∫–∞"):
                results = [
                    InlineQueryResultArticle(
                        id=str(uuid4()),
                        title="–ü–µ—Ä–∞–∫–ª–∞–¥ –Ω–∞ –±–µ–ª–∞—Ä—É—Å–∫—É—é (–î–∞–∫–ª–∞–¥–Ω–∞)",
                        input_message_content=InputTextMessageContent(be),
                        description=be[:120]
                    )
                ]
                await update.inline_query.answer(results, cache_time=0, is_personal=True)
                return
        
        # –ï—Å–ª–∏ —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
        be = fallback_tr.translate_ru_to_be(query)
        if not be or be.startswith("–ü–µ—Ä–∞–∫–ª–∞–¥ –Ω–µ –∑–Ω–æ–π–¥–∑–µ–Ω—ã"):
            be = "–ü–µ—Ä–∞–∫–ª–∞–¥ –Ω–µ –∞—Ç—Ä—ã–º–∞—û—Å—è"
        
        results = [
            InlineQueryResultArticle(
                id=str(uuid4()),
                title="–ü–µ—Ä–∞–∫–ª–∞–¥ –Ω–∞ –±–µ–ª–∞—Ä—É—Å–∫—É—é (Fallback)",
                input_message_content=InputTextMessageContent(be),
                description=be[:120]
            )
        ]
        await update.inline_query.answer(results, cache_time=0, is_personal=True)
        
    except Exception as e:
        results = [
            InlineQueryResultArticle(
                id=str(uuid4()),
                title="–ü–∞–º—ã–ª–∫–∞ –ø–µ—Ä–∞–∫–ª–∞–¥—É",
                input_message_content=InputTextMessageContent(f"–ü–∞–º—ã–ª–∫–∞: {e}"),
                description="–ü—Ä–∞–≤–µ—Ä—Ü–µ —Ç—ç–∫—Å—Ç —ñ –ø–∞—Å–ø—Ä–∞–±—É–π—Ü–µ –∑–Ω–æ—û"
            )
        ]
        await update.inline_query.answer(results, cache_time=0, is_personal=True)

def main():
    token = load_or_ask_token()
    print("üîß Debug info:")
    print(f"  Python: {platform.python_version()} ({platform.system()} {platform.machine()})")
    print(f"  Torch: {torch.__version__}")
    print(f"  Transformers: {_tf.__version__}")
    print(f"  HF Hub: {_hf.__version__}")
    print(f"  HF_ENDPOINT={os.getenv('HF_ENDPOINT','')}")
    print(f"  HF_LOCAL_ONLY={os.getenv('HF_LOCAL_ONLY','0')}")
    print(f"  RU_BE_MODEL={os.getenv('RU_BE_MODEL','Helsinki-NLP/opus-mt-ru-be')}")
    print(f"  HF_CACHE_DIR={os.getenv('HF_CACHE_DIR', os.path.expanduser('~/.cache/huggingface'))}")
    print(f"  HTTPS_PROXY={os.getenv('HTTPS_PROXY','')}")
    print(f"  HTTP_PROXY={os.getenv('HTTP_PROXY','')}")
    app = Application.builder().token(token).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("debug", debug_cmd))
    app.add_handler(CommandHandler("status", status_cmd))
    app.add_handler(CommandHandler("test", test_cmd))
    app.add_handler(InlineQueryHandler(on_inline_query))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    print("üéØ –ë–æ—Ç –¥–∞–∫–ª–∞–¥–Ω–∞–≥–∞ –ø–µ—Ä–∞–∫–ª–∞–¥—É –∑–∞–ø—É—â–µ–Ω. –ù–∞–±–µ—Ä–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.")
    print(f"üí° –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å: {os.getenv('RU_BE_MODEL', 'Helsinki-NLP/opus-mt-ru-be')}")
    app.run_polling(close_loop=False)

if __name__ == "__main__":
    main()
